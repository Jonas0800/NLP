{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf129165",
   "metadata": {},
   "source": "# Übungen CH11"
  },
  {
   "cell_type": "markdown",
   "id": "7ab174cb",
   "metadata": {},
   "source": "## Aufgabe 1"
  },
  {
   "cell_type": "code",
   "id": "e977d236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:41:57.656488Z",
     "start_time": "2025-07-18T19:41:57.653641Z"
    }
   },
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def add_cv_field_after_lx(entry):\n",
    "    for idx, field in enumerate(list(entry)):\n",
    "        if field.tag == 'lx':\n",
    "            cv_elem = Element('cv')\n",
    "            cv_elem.text = cv(field.text)  # cv() aus §5.1\n",
    "            entry.insert(idx+1, cv_elem)\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "bd52fa61",
   "metadata": {},
   "source": "## Aufgabe 2\n"
  },
  {
   "cell_type": "code",
   "id": "38155e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:41:59.202379Z",
     "start_time": "2025-07-18T19:41:59.199223Z"
    }
   },
   "source": [
    "def delete_field(entry, tag):\n",
    "    \"\"\"Löscht alle Subelemente mit dem angegebenen Tag aus entry.\"\"\"\n",
    "    for field in list(entry):\n",
    "        if field.tag == tag:\n",
    "            entry.remove(field)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "252af8cf",
   "metadata": {},
   "source": "## Aufgabe 3"
  },
  {
   "cell_type": "code",
   "id": "33454edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:00.634525Z",
     "start_time": "2025-07-18T19:42:00.630711Z"
    }
   },
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "LEGAL_POS = {'n', 'v.t.', 'v.i.', 'adj', 'det'}\n",
    "pattern = re.compile(r\"font-size:11.0pt'>([a-z.]+)<\")\n",
    "\n",
    "def report_illegal_pos(html_file):\n",
    "    doc = open(html_file, encoding=\"windows-1252\").read()\n",
    "    matches = set(re.findall(pattern, doc))\n",
    "    illegal = matches - LEGAL_POS\n",
    "    print(\"Illegale POS-Felder:\", illegal)\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "    for p in soup.find_all('p'):\n",
    "        m = pattern.search(str(p))\n",
    "        if m and m.group(1) in illegal:\n",
    "            head = p.get_text().split()[0]\n",
    "            print(\" →\", head)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "97d88d07",
   "metadata": {},
   "source": "## Aufgabe 4"
  },
  {
   "cell_type": "code",
   "id": "00147096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:02.508248Z",
     "start_time": "2025-07-18T19:42:02.443761Z"
    }
   },
   "source": [
    "from nltk.corpus import toolbox\n",
    "from collections import Counter\n",
    "\n",
    "def rare_pos(lex_file):\n",
    "    lex = toolbox.xml(lex_file)\n",
    "    counts = Counter(e.findtext('ps') for e in lex if e.find('ps') is not None)\n",
    "    return [ps for ps, cnt in counts.items() if cnt < 10]\n",
    "\n",
    "print(rare_pos('rotokas.dic'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLASS', 'FFP', 'NUM', 'POST', 'EXCL']\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "467f179a",
   "metadata": {},
   "source": "## Aufgabe 5"
  },
  {
   "cell_type": "code",
   "id": "d8c90197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:04.289673Z",
     "start_time": "2025-07-18T19:42:04.257637Z"
    }
   },
   "source": [
    "import re\n",
    "from nltk.corpus import toolbox\n",
    "\n",
    "def has_partial_redup(word):\n",
    "    if not word:\n",
    "        return False\n",
    "    return bool(re.search(r'(.{2,})\\1', word))\n",
    "\n",
    "words = [e.findtext('lx') for e in toolbox.xml('rotokas.dic')]\n",
    "candidates = [w for w in words if has_partial_redup(w)]\n",
    "print(candidates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kaakaaro', 'kaakaaviko', 'kaakaavo', 'kaekae', 'kaekae', 'kaekaearo', 'kaekaeo', 'kaekaesoto', 'kaekaevira', 'kaikaio', 'kairiro', 'kaitutu', 'kaitutupie', 'kaitutuvira', 'kakae', 'kakae', 'kakae', 'kakaevira', 'kakapikoa', 'kakapikoto', 'kakapu', 'kakapua', 'kakara', 'kakarau', 'kakata', 'kakate', 'kakatuara', 'kakau', 'kakauoa', 'kakavea', 'kakavoro', 'kakavu', 'kakiaki', 'kakuaku', 'kaokao', 'kaokaoara', 'kaokaoto', 'kapekape', 'kapekapevira', 'kapikapi', 'kapokapo', 'kapokapoa', 'kapokapora', 'kapokaporo', 'kapuasisi', 'karakarao', 'karakaraoa', 'karakaraoto', 'karakaraovira', 'karakuku', 'karara', 'karekare', 'karekare', 'karekarererava', 'karekareto', 'karikari', 'karokaropo', 'karukaru', 'Karuru', 'kasikasi', 'katakatai', 'katakataivira', 'katokato', 'katokatoto', 'katokatovira', 'katoto', 'katukatu', 'kaukau', 'kaukaupie', 'kaukauvira', 'kauokauo', 'kavakavau', 'kavikavi', 'kavikaviru', 'kavikaviru', 'kavokavo', 'kavokavoa', 'kavokavoto', 'kavovoa', 'kavovovira', 'keakea', 'keakeato', 'keekee', 'keekeepa', 'keekeeri', 'keekeerito', 'keke', 'keke', 'kekepie', 'kekeputu', 'kekeputuvira', 'kekeraokovira', 'kekesopa', 'kekevoto', 'kekevotovira', 'kepikepi', 'kerakera', 'kerere', 'kerereua', 'kerikerisi', 'keroroi', 'kiki', 'kiki', 'kikipi', 'kikipisi', 'kikira', 'kikiraeko', 'kikisi', 'kikisikae', 'kikisiova', 'kikitausi', 'kipekipe', 'kipekipea', 'kipukipu', 'kirikaokao', 'kirokiro', 'kirokiro', 'kirokiropato', 'kirukiru', 'kirukirua', 'kitukitu', 'koakoa', 'koakoa', 'koekoe', 'koekoeto', 'koikoi', 'koikoipato', 'koikoipie', 'koikoito', 'koko', 'koko', 'kokoi', 'kokoisi', 'kokokoru', 'kokoo', 'kokooko', 'kokookoa', 'kokoote', 'kokootu', 'kokopa', 'kokopakou', 'kokopeko', 'kokopekovira', 'kokopeoto', 'kokopuoto', 'kokopuovira', 'kokopuvira', 'kokora', 'kokorai', 'kokorato', 'kokori', 'kokorivira', 'kokoro', 'kokoroki', 'kokoroku', 'kokorokupie', 'kokoropato', 'kokorosi', 'kokorovira', 'kokoru', 'kokoruu', 'kokoruu', 'kokosi', 'kokosi', 'kokosito', 'kokosiva', 'kokotagoe', 'kokote', 'kokoto', 'kokotu', 'kokotua', 'kokotuo', 'kokovae', 'kokovaeva', 'kokovara', 'kokovara', 'kokovaravira', 'kokovu', 'kokovua', 'kokovua', 'kokovua', 'kokovupaparie', 'kokovurito', 'kokuoku', 'kookoo', 'kookooia', 'kookoopeko', 'kookoopi', 'koopipi', 'kootutu', 'kopakopa', 'kopikopi', 'kopikopiara', 'kopipi', 'kopukopu', 'kopukopua', 'korara', 'koraraoko', 'Korere', 'korereto', 'korikori', 'korikoripava', 'kororo', 'kororo', 'kororoisivira', 'kororovi', 'kororovivira', 'kororu', 'kororupie', 'korukoru', 'korukorupato', 'kosikosi', 'kosikosi', 'kotokoto', 'kotokotoara', 'kotukotu', 'koukou', 'koukouo', 'koukouo', 'kovakovara', 'Kovava', 'kovekove', 'kovokovo', 'kovokovo', 'kovokovo', 'kovokovoa', 'kovovo', 'kovukovu', 'kovukovuto', 'kovukovuvira', 'kukiuki', 'kukiukia', 'kuku', 'kukua', 'kukuaua', 'kukue', 'kukue pute', 'kukuepaa', 'kukuku', 'kukupira', 'kukuriko', 'kukurikoto', 'kukusiri', 'kukutauvu', 'kukutu', 'kukuuku', 'kukuukua', 'kukuukupie', 'kukuuvua', 'kukuvai', 'kukuvaipaa', 'kukuvita', 'kukuvua', 'kupekupe', 'kupekupepa', 'kupukupu', 'kurikaakaakuto', 'kurikoko', 'kurikuri', 'kurokuro', 'kurokuroto', 'kururai', 'kururu', 'kuukuuvu', 'kuukuuvuto', 'kuuvuvira', 'kuvukuvu', 'kuvukuvua']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "9a55e3a1",
   "metadata": {},
   "source": "## Aufgabe 6"
  },
  {
   "cell_type": "code",
   "id": "7ec73474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:06.451140Z",
     "start_time": "2025-07-18T19:42:06.448042Z"
    }
   },
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def update_cv_field(entry):\n",
    "    # Vorhandenes <cv> entfernen\n",
    "    for f in list(entry):\n",
    "        if f.tag == 'cv':\n",
    "            entry.remove(f)\n",
    "    # Neues <cv> nach <lx> einfügen\n",
    "    for idx, field in enumerate(list(entry)):\n",
    "        if field.tag == 'lx':\n",
    "            cv_elem = Element('cv')\n",
    "            cv_elem.text = cv(field.text)\n",
    "            entry.insert(idx+1, cv_elem)\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "3c7e8f39",
   "metadata": {},
   "source": "## Aufgabe 7"
  },
  {
   "cell_type": "code",
   "id": "e6aeb12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:08.131072Z",
     "start_time": "2025-07-18T19:42:08.127652Z"
    }
   },
   "source": [
    "import re\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def add_syl_field(entry):\n",
    "    lx = entry.findtext('lx', '').lower()\n",
    "    syl_count = len(re.findall(r'[aeiou]+', lx))\n",
    "    syl_elem = Element('syl')\n",
    "    syl_elem.text = str(syl_count)\n",
    "    for idx, field in enumerate(list(entry)):\n",
    "        if field.tag == 'lx':\n",
    "            entry.insert(idx+1, syl_elem)\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "cc9f1c5a",
   "metadata": {},
   "source": "## Aufgabe 8"
  },
  {
   "cell_type": "code",
   "id": "ed036238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:10.466647Z",
     "start_time": "2025-07-18T19:42:10.403233Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk import Index, edit_distance\n",
    "from nltk.corpus import toolbox\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "\n",
    "def signature(word):\n",
    "    vowels = set('aeiou')\n",
    "    return ''.join('V' if c.lower() in vowels else 'C' for c in word if c.isalpha())\n",
    "\n",
    "def entry_to_sfm(entry):\n",
    "    lines = []\n",
    "    for child in entry:\n",
    "        tag = child.tag\n",
    "        text = child.text or ''\n",
    "        lines.append(f\"\\\\{tag} {text}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "entries = toolbox.xml('rotokas.dic')\n",
    "lexemes = [e.findtext('lx') for e in entries if e.findtext('lx')]\n",
    "\n",
    "signatures = Index((signature(w), w) for w in lexemes)\n",
    "\n",
    "def show_entry(lexeme):\n",
    "    if lexeme in lexemes:\n",
    "        entry = entries[lexemes.index(lexeme)]\n",
    "    else:\n",
    "        sig = signature(lexeme)\n",
    "        candidates = signatures[sig] or lexemes\n",
    "        best = min(candidates, key=lambda w: edit_distance(lexeme, w))\n",
    "        print(f\"(verwende '{best}' als ähnlichsten Treffer)\")\n",
    "        entry = entries[lexemes.index(best)]\n",
    "    print(entry_to_sfm(entry))\n",
    "\n",
    "show_entry('musci')     \n",
    "print()\n",
    "show_entry('redundant')  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(verwende 'Kusi' als ähnlichsten Treffer)\n",
      "\\lx kurutu\n",
      "\\ps N\n",
      "\\pt NT\n",
      "\\ge portion\n",
      "\\ge part of\n",
      "\\tkp ???\n",
      "\\dt 04/Dec/2004\n",
      "\\ex Uuko kurutu vateri eva.\n",
      "\\xp ???\n",
      "\\xe Give that half full cup of water (to him).\n",
      "\\ex Uko kurutu vateri eva ragai-pa.\n",
      "\\xp Yu givim hap wara long mi.\n",
      "\\xe ???\n",
      "\n",
      "(verwende 'keruiato' als ähnlichsten Treffer)\n",
      "\\lx kerui\n",
      "\\ps V\n",
      "\\pt A\n",
      "\\ge thin\n",
      "\\ge bony\n",
      "\\ge skinny\n",
      "\\tkp bun nating\n",
      "\\vx 1\n",
      "\\dt 28/Oct/2005\n",
      "\\ex Em ro ira viapau sopeiavoi toupa.\n",
      "\\xp Man i no gat mit i blong bodi.\n",
      "\\xe ???\n",
      "\\ex Ragaia keruito ragoa-ia viapau varuaravai toupaveira ora aue tuga ragai vararo-ia.\n",
      "\\xp Mi bun nating man mi nogat mit na gris istap long bodi bilong mi.\n",
      "\\xe ???\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "90626469",
   "metadata": {},
   "source": "## Aufgabe 9"
  },
  {
   "cell_type": "code",
   "id": "0ce45f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:13.638288Z",
     "start_time": "2025-07-18T19:42:13.605288Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import toolbox\n",
    "\n",
    "def freq_field_pairs(lex_file):\n",
    "    lex = toolbox.xml(lex_file)\n",
    "    pairs = Counter()\n",
    "    for entry in lex:\n",
    "        tags = [f.tag for f in entry]\n",
    "        pairs.update(zip(tags, tags[1:]))\n",
    "    return pairs.most_common()\n",
    "\n",
    "print(freq_field_pairs('rotokas.dic'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('ex', 'xp'), 1532), (('xp', 'xe'), 1526), (('ps', 'pt'), 835), (('ge', 'tkp'), 824), (('pt', 'ge'), 766), (('dt', 'ex'), 758), (('xe', 'ex'), 708), (('lx', 'ps'), 520), (('rt', 'ps'), 356), (('tkp', 'dt'), 327), (('lx', 'rt'), 313), (('ge', 'ge'), 287), (('eng', 'eng'), 143), (('cmt', 'dt'), 143), (('tkp', 'nt'), 130), (('vx', 'dt'), 119), (('arg', 'vx'), 108), (('nt', 'dt'), 107), (('tkp', 'vx'), 102), (('tkp', 'eng'), 82), (('tkp', 'cmt'), 78), (('tkp', 'tkp'), 69), (('tkp', 'arg'), 67), (('ge', 'eng'), 66), (('eng', 'tkp'), 61), (('vx', 'arg'), 59), (('lx', 'alt'), 54), (('ps', 'ge'), 48), (('dt', 'cmt'), 46), (('alt', 'rt'), 46), (('cmt', 'ex'), 45), (('vx', 'cmt'), 43), (('arg', 'dt'), 40), (('vx', 'sc'), 38), (('sf', 'dt'), 36), (('sc', 'dt'), 31), (('eng', 'dt'), 30), (('dx', 'ge'), 30), (('rdp', 'ge'), 28), (('pt', 'rdp'), 25), (('pt', 'dx'), 25), (('nt', 'sf'), 21), (('nt', 'cmt'), 19), (('tkp', 'dcsv'), 18), (('tkp', 'sf'), 18), (('dcsv', 'vx'), 15), (('cmt', 'vx'), 15), (('eng', 'arg'), 14), (('arg', 'cmt'), 14), (('sc', 'cmt'), 13), (('sc', 'vx'), 13), (('vx', 'nt'), 13), (('tkp', 'avm'), 13), (('tkp', 'cm'), 13), (('tkp', 'sc'), 12), (('sf', 'nt'), 12), (('eng', 'vx'), 11), (('avm', 'dt'), 11), (('eng', 'nt'), 10), (('nt', 'sa'), 9), (('cm', 'arg'), 9), (('sa', 'dt'), 9), (('pt', 'sn'), 8), (('ig', 'dt'), 8), (('alt', 'ps'), 8), (('pt', 'cl'), 7), (('cl', 'ge'), 7), (('eng', 'cmt'), 7), (('dcsv', 'dt'), 7), (('sa', 'sf'), 7), (('rdp', 'ex'), 7), (('nt', 'arg'), 7), (('sn', 'ge'), 6), (('tkp', 'dx'), 6), (('dx', 'dt'), 6), (('dt', 'rdp'), 6), (('cm', 'vx'), 6), (('vx', 'dcsv'), 5), (('cmt', 'arg'), 5), (('vx', 'ex'), 5), (('dt', 'vx'), 5), (('pt', 'dt'), 5), (('tkp', 'pt'), 4), (('eng', 'ge'), 4), (('tkp', 'ig'), 4), (('ps', 'dx'), 4), (('nt', 'vx'), 4), (('arg', 'sc'), 4), (('eng', 'sa'), 4), (('nt', 'pt'), 4), (('cmt', 'nt'), 3), (('tkp', 'am'), 3), (('cmt', 'sc'), 3), (('eng', 'ig'), 3), (('cmt', 'dcsv'), 3), (('dt', 'arg'), 3), (('dcpv', 'dt'), 3), (('avm', 'sc'), 3), (('sc', 'dcpv'), 3), (('nt', 'ig'), 3), (('sc', 'ex'), 3), (('cmt', 'sa'), 3), (('dt', 'sf'), 2), (('sf', 'ex'), 2), (('sf', 'cmt'), 2), (('am', 'dcsv'), 2), (('dcsv', 'am'), 2), (('ig', 'nt'), 2), (('tkp', 'sa'), 2), (('sn', 'rdp'), 2), (('vx', 'dcpv'), 2), (('tkp', 'ge'), 2), (('vx', 'cm'), 2), (('dt', 'alt'), 2), (('alt', 'ex'), 2), (('tkp', 'dcpv'), 2), (('dcpv', 'vx'), 2), (('dcsv', 'arg'), 2), (('cmt', 'cm'), 2), (('arg', 'nt'), 2), (('am', 'vx'), 2), (('xe', 'dt'), 2), (('pt', 'eng'), 2), (('cmt', 'sf'), 2), (('eng', 'am'), 2), (('cm', 'dt'), 2), (('sc', 'nt'), 2), (('am', 'arg'), 2), (('rt', 'rdp'), 2), (('rdp', 'ps'), 2), (('sa', 'sc'), 2), (('_sh', '_DateStampHasFourDigitYear'), 1), (('pt', 'sf'), 1), (('ps', 'rdp'), 1), (('am', 'cmt'), 1), (('nt', 'dcsv'), 1), (('ge', 'dt'), 1), (('sa', 'vx'), 1), (('eng', 'dcsv'), 1), (('dx', 'dx'), 1), (('pt', 'ig'), 1), (('ig', 'ge'), 1), (('ge', 'vx'), 1), (('cm', 'cmt'), 1), (('dcpv', 'cmt'), 1), (('dcsv', 'cm'), 1), (('eng', 'cm'), 1), (('cm', 'am'), 1), (('cm', 'sa'), 1), (('xp', 'xp'), 1), (('xe', 'xp'), 1), (('rt', 'ge'), 1), (('dcpv', 'dadv'), 1), (('dadv', 'dt'), 1), (('dt', 'nt'), 1), (('rt', 'rt'), 1), (('rt', 'wf'), 1), (('wf', 'wf'), 1), (('wf', 'ps'), 1), (('dx', 'vx'), 1), (('lx', 'cl'), 1), (('cl', 'ps'), 1), (('eng', 'sf'), 1), (('cmt', 'cmt'), 1), (('dt', 'sa'), 1), (('sa', 'cmt'), 1), (('tkp', 'rdp'), 1), (('rdp', 'arg'), 1), (('tkp', 'ex'), 1), (('dt', 'sc'), 1), (('dcsv', 'ex'), 1), (('eng', 'avm'), 1), (('pt', 'sa'), 1), (('sa', 'sa'), 1), (('pt', 'vx'), 1), (('vx', 'dx'), 1), (('dt', 'am'), 1), (('am', 'ex'), 1), (('ge', 'nt'), 1), (('dcsv', 'cmt'), 1), (('sa', 'dx'), 1), (('arg', 'cm'), 1), (('dcsv', 'sc'), 1), (('lx', 'wf'), 1), (('wf', 'rt'), 1), (('pt', 'cmt'), 1), (('nt', 'sc'), 1), (('alt', 'alt'), 1), (('am', 'dt'), 1), (('cmt', 'rdp'), 1)]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "33ebaead",
   "metadata": {},
   "source": "## Aufgabe 10"
  },
  {
   "cell_type": "code",
   "id": "84e03e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:15.689048Z",
     "start_time": "2025-07-18T19:42:15.685585Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_toolbox(csv_file):\n",
    "    with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for head, pos, gloss in reader:\n",
    "            print(f\"\\\\lx {head}\")\n",
    "            print(f\"\\\\ps {pos}\")\n",
    "            print(f\"\\\\gl {gloss}\")\n",
    "            print()"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "f5f14dd3",
   "metadata": {},
   "source": "## Aufgabe 11"
  },
  {
   "cell_type": "code",
   "id": "bbabb92c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:17.554554Z",
     "start_time": "2025-07-18T19:42:17.488480Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk import Index\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "\n",
    "def index_shakespeare_words():\n",
    "    path = nltk.data.find('corpora/shakespeare/merchant.xml')\n",
    "    merchant = ElementTree().parse(path)\n",
    "    entries = []\n",
    "    for i, act in enumerate(merchant.findall('ACT')):\n",
    "        for j, scene in enumerate(act.findall('SCENE')):\n",
    "            for k, speech in enumerate(scene.findall('SPEECH')):\n",
    "                location = (i+1, j+1, k+1)\n",
    "                text = ' '.join(line.text or '' for line in speech.findall('LINE'))\n",
    "                tokens = nltk.word_tokenize(text)\n",
    "                for w in tokens:\n",
    "                    if any(ch.isalpha() for ch in w):\n",
    "                        entries.append((w.lower(), location))\n",
    "    return Index(entries)\n",
    "\n",
    "idx = index_shakespeare_words()\n",
    "print(idx['music'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 2, 9), (3, 2, 9), (3, 2, 9), (3, 2, 9), (5, 1, 23), (5, 1, 23), (5, 1, 23), (5, 1, 24), (5, 1, 25), (5, 1, 25), (5, 1, 25), (5, 1, 25), (5, 1, 25), (5, 1, 28), (5, 1, 29)]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "3af360fd",
   "metadata": {},
   "source": "## Aufgabe 12"
  },
  {
   "cell_type": "code",
   "id": "6b94277b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:42:19.575022Z",
     "start_time": "2025-07-18T19:42:19.521913Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk import ConditionalFreqDist\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "\n",
    "path = nltk.data.find('corpora/shakespeare/merchant.xml')\n",
    "merchant = ElementTree().parse(path)\n",
    "\n",
    "cfd = ConditionalFreqDist()\n",
    "for speech in merchant.findall('ACT/SCENE/SPEECH'):\n",
    "    speaker = speech.findtext('SPEAKER') or 'UNKNOWN'\n",
    "    text = ' '.join(line.text or '' for line in speech.findall('LINE'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    length = len(tokens)\n",
    "    cfd[speaker][length] += 1\n",
    "\n",
    "print(cfd['PORTIA'][12])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
